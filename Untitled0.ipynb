{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRS4yaXdsYYylL6YScxhvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaushikDasarii/kaushik/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load the dataset locally or from URL if you're running on your system\n",
        "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT8WGPMYm2Zu",
        "outputId": "84738bf8-20c0-49a1-b433-328c2d8291d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO REPRESENT IN 0'S AND 1'S**"
      ],
      "metadata": {
        "id": "w4Qh97qvq2bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Step 1: Load dataset with headers\n",
        "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "X = df.drop(\"Outcome\", axis=1).values\n",
        "y = df[\"Outcome\"].values\n",
        "\n",
        "# Step 2: Split into train & test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 3: Define all models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'SVM': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Step 4: Evaluate all models\n",
        "print(\" Evaluation Before GridSearchCV:\")\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = acc\n",
        "    print(f\"\\n Model: {name}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 5: Select top 2 models\n",
        "top2 = sorted(results, key=results.get, reverse=True)[:2]\n",
        "print(\"\\n Top 2 Models:\", top2)\n",
        "\n",
        "# Step 6: Param grids only for top 2\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__max_depth': [None, 5, 10]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'model__C': [0.1, 1, 10],\n",
        "        'model__kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10],\n",
        "        'model__penalty': ['l2'],\n",
        "        'model__solver': ['liblinear']\n",
        "    },\n",
        "    'KNN': {\n",
        "        'model__n_neighbors': [3, 5, 7, 9],\n",
        "        'model__weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model__n_estimators': [50, 100],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.2]\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model__max_depth': [None, 5, 10],\n",
        "        'model__criterion': ['gini', 'entropy']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 7: Apply GridSearchCV to top 2\n",
        "print(\"\\n GridSearchCV for Top 2 Models:\")\n",
        "for name in top2:\n",
        "    model = models[name]\n",
        "    grid = GridSearchCV(\n",
        "        Pipeline([('scaler', StandardScaler()), ('model', model)]),\n",
        "        param_grid=param_grids[name],\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n GridSearchCV: {name}\")\n",
        "    print(\"Best Params:\", grid.best_params_)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FVx-q0Aqd6Z",
        "outputId": "df35d909-3669-4163-b0f0-74f833f77fff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Evaluation Before GridSearchCV:\n",
            "\n",
            "🧠 Model: Logistic Regression\n",
            "Accuracy: 0.7143\n",
            "Confusion Matrix:\n",
            " [[82 18]\n",
            " [26 28]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       100\n",
            "           1       0.61      0.52      0.56        54\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.68      0.67      0.67       154\n",
            "weighted avg       0.71      0.71      0.71       154\n",
            "\n",
            "\n",
            "🧠 Model: SVM\n",
            "Accuracy: 0.7532\n",
            "Confusion Matrix:\n",
            " [[83 17]\n",
            " [21 33]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.81       100\n",
            "           1       0.66      0.61      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "\n",
            "🧠 Model: Decision Tree\n",
            "Accuracy: 0.7273\n",
            "Confusion Matrix:\n",
            " [[86 14]\n",
            " [28 26]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.86      0.80       100\n",
            "           1       0.65      0.48      0.55        54\n",
            "\n",
            "    accuracy                           0.73       154\n",
            "   macro avg       0.70      0.67      0.68       154\n",
            "weighted avg       0.72      0.73      0.72       154\n",
            "\n",
            "\n",
            "🧠 Model: Random Forest\n",
            "Accuracy: 0.7532\n",
            "Confusion Matrix:\n",
            " [[86 14]\n",
            " [24 30]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82       100\n",
            "           1       0.68      0.56      0.61        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.71      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "\n",
            "🧠 Model: Gradient Boosting\n",
            "Accuracy: 0.7532\n",
            "Confusion Matrix:\n",
            " [[84 16]\n",
            " [22 32]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.84      0.82       100\n",
            "           1       0.67      0.59      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "\n",
            "🧠 Model: KNN\n",
            "Accuracy: 0.7013\n",
            "Confusion Matrix:\n",
            " [[80 20]\n",
            " [26 28]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.78       100\n",
            "           1       0.58      0.52      0.55        54\n",
            "\n",
            "    accuracy                           0.70       154\n",
            "   macro avg       0.67      0.66      0.66       154\n",
            "weighted avg       0.69      0.70      0.70       154\n",
            "\n",
            "\n",
            "🧠 Model: Naive Bayes\n",
            "Accuracy: 0.7078\n",
            "Confusion Matrix:\n",
            " [[74 26]\n",
            " [19 35]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.74      0.77       100\n",
            "           1       0.57      0.65      0.61        54\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.68      0.69      0.69       154\n",
            "weighted avg       0.72      0.71      0.71       154\n",
            "\n",
            "\n",
            "✅ Top 2 Models: ['SVM', 'Random Forest']\n",
            "\n",
            "🔹 GridSearchCV for Top 2 Models:\n",
            "\n",
            "🔍 GridSearchCV: SVM\n",
            "Best Params: {'model__C': 0.1, 'model__kernel': 'linear'}\n",
            "Accuracy: 0.7208\n",
            "Confusion Matrix:\n",
            " [[83 17]\n",
            " [26 28]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.83      0.79       100\n",
            "           1       0.62      0.52      0.57        54\n",
            "\n",
            "    accuracy                           0.72       154\n",
            "   macro avg       0.69      0.67      0.68       154\n",
            "weighted avg       0.71      0.72      0.71       154\n",
            "\n",
            "\n",
            "🔍 GridSearchCV: Random Forest\n",
            "Best Params: {'model__max_depth': 5, 'model__n_estimators': 200}\n",
            "Accuracy: 0.7208\n",
            "Confusion Matrix:\n",
            " [[84 16]\n",
            " [27 27]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.84      0.80       100\n",
            "           1       0.63      0.50      0.56        54\n",
            "\n",
            "    accuracy                           0.72       154\n",
            "   macro avg       0.69      0.67      0.68       154\n",
            "weighted avg       0.71      0.72      0.71       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHANGE THE 0 AND 1 INTO NAMES BY TARGET NAME AND EXECUTE**"
      ],
      "metadata": {
        "id": "xQTTfGvCrPau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Step 1: Load dataset with headers\n",
        "url = \"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "########################## Define the target names for the classification report\n",
        "target_names = ['No Diabetes', 'Diabetes'] # Assuming 0 is 'No Diabetes' and 1 is 'Diabetes'\n",
        "\n",
        "X = df.drop(\"Outcome\", axis=1).values\n",
        "y = df[\"Outcome\"].values\n",
        "\n",
        "# Step 2: Split into train & test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 3: Define all models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'SVM': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Step 4: Evaluate all models\n",
        "print(\" Evaluation Before GridSearchCV:\")\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = acc\n",
        "    print(f\"\\n Model: {name}\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred,target_names=target_names))\n",
        "\n",
        "# Step 5: Select top 2 models\n",
        "top2 = sorted(results, key=results.get, reverse=True)[:2]\n",
        "print(\"\\n✅ Top 2 Models:\", top2)\n",
        "\n",
        "# Step 6: Param grids only for top 2\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__max_depth': [None, 5, 10]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'model__C': [0.1, 1, 10],\n",
        "        'model__kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10],\n",
        "        'model__penalty': ['l2'],\n",
        "        'model__solver': ['liblinear']\n",
        "    },\n",
        "    'KNN': {\n",
        "        'model__n_neighbors': [3, 5, 7, 9],\n",
        "        'model__weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model__n_estimators': [50, 100],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.2]\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model__max_depth': [None, 5, 10],\n",
        "        'model__criterion': ['gini', 'entropy']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 7: Apply GridSearchCV to top 2\n",
        "print(\"\\n🔹 GridSearchCV for Top 2 Models:\")\n",
        "for name in top2:\n",
        "    model = models[name]\n",
        "    grid = GridSearchCV(\n",
        "        Pipeline([('scaler', StandardScaler()), ('model', model)]),\n",
        "        param_grid=param_grids[name],\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n GridSearchCV: {name}\")\n",
        "    print(\"Best Params:\", grid.best_params_)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred,target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOzJLRAxrDII",
        "outputId": "c46f0152-96d0-4388-fff5-4014a6626ed8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Evaluation Before GridSearchCV:\n",
            "\n",
            "🧠 Model: Logistic Regression\n",
            "Accuracy: 0.7143\n",
            "Confusion Matrix:\n",
            " [[82 18]\n",
            " [26 28]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.76      0.82      0.79       100\n",
            "    Diabetes       0.61      0.52      0.56        54\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.68      0.67      0.67       154\n",
            "weighted avg       0.71      0.71      0.71       154\n",
            "\n",
            "\n",
            "🧠 Model: SVM\n",
            "Accuracy: 0.7532\n",
            "Confusion Matrix:\n",
            " [[83 17]\n",
            " [21 33]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.80      0.83      0.81       100\n",
            "    Diabetes       0.66      0.61      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "\n",
            "🧠 Model: Decision Tree\n",
            "Accuracy: 0.7208\n",
            "Confusion Matrix:\n",
            " [[86 14]\n",
            " [29 25]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.75      0.86      0.80       100\n",
            "    Diabetes       0.64      0.46      0.54        54\n",
            "\n",
            "    accuracy                           0.72       154\n",
            "   macro avg       0.69      0.66      0.67       154\n",
            "weighted avg       0.71      0.72      0.71       154\n",
            "\n",
            "\n",
            "🧠 Model: Random Forest\n",
            "Accuracy: 0.7403\n",
            "Confusion Matrix:\n",
            " [[81 19]\n",
            " [21 33]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.79      0.81      0.80       100\n",
            "    Diabetes       0.63      0.61      0.62        54\n",
            "\n",
            "    accuracy                           0.74       154\n",
            "   macro avg       0.71      0.71      0.71       154\n",
            "weighted avg       0.74      0.74      0.74       154\n",
            "\n",
            "\n",
            "🧠 Model: Gradient Boosting\n",
            "Accuracy: 0.7532\n",
            "Confusion Matrix:\n",
            " [[84 16]\n",
            " [22 32]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.79      0.84      0.82       100\n",
            "    Diabetes       0.67      0.59      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "\n",
            "🧠 Model: KNN\n",
            "Accuracy: 0.7013\n",
            "Confusion Matrix:\n",
            " [[80 20]\n",
            " [26 28]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.75      0.80      0.78       100\n",
            "    Diabetes       0.58      0.52      0.55        54\n",
            "\n",
            "    accuracy                           0.70       154\n",
            "   macro avg       0.67      0.66      0.66       154\n",
            "weighted avg       0.69      0.70      0.70       154\n",
            "\n",
            "\n",
            "🧠 Model: Naive Bayes\n",
            "Accuracy: 0.7078\n",
            "Confusion Matrix:\n",
            " [[74 26]\n",
            " [19 35]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.80      0.74      0.77       100\n",
            "    Diabetes       0.57      0.65      0.61        54\n",
            "\n",
            "    accuracy                           0.71       154\n",
            "   macro avg       0.68      0.69      0.69       154\n",
            "weighted avg       0.72      0.71      0.71       154\n",
            "\n",
            "\n",
            "✅ Top 2 Models: ['SVM', 'Gradient Boosting']\n",
            "\n",
            "🔹 GridSearchCV for Top 2 Models:\n",
            "\n",
            "🔍 GridSearchCV: SVM\n",
            "Best Params: {'model__C': 0.1, 'model__kernel': 'linear'}\n",
            "Accuracy: 0.7208\n",
            "Confusion Matrix:\n",
            " [[83 17]\n",
            " [26 28]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.76      0.83      0.79       100\n",
            "    Diabetes       0.62      0.52      0.57        54\n",
            "\n",
            "    accuracy                           0.72       154\n",
            "   macro avg       0.69      0.67      0.68       154\n",
            "weighted avg       0.71      0.72      0.71       154\n",
            "\n",
            "\n",
            "🔍 GridSearchCV: Gradient Boosting\n",
            "Best Params: {'model__learning_rate': 0.1, 'model__n_estimators': 50}\n",
            "Accuracy: 0.7532\n",
            "Confusion Matrix:\n",
            " [[84 16]\n",
            " [22 32]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " No Diabetes       0.79      0.84      0.82       100\n",
            "    Diabetes       0.67      0.59      0.63        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final best model after GridSearchCV\n",
        "final_model = best_model  # Best model from loop above\n",
        "\n",
        "# ✍️ Ask for input\n",
        "print(\"\\n Enter patient details to predict diabetes (input numbers as prompted):\")\n",
        "input_data = []\n",
        "features = df.columns[:-1]  # Exclude 'Outcome'\n",
        "\n",
        "for feature in features:\n",
        "    value = float(input(f\"Enter {feature}: \"))\n",
        "    input_data.append(value)\n",
        "\n",
        "#  Reshape and scale using the pipeline\n",
        "import numpy as np\n",
        "input_array = np.array(input_data).reshape(1, -1)\n",
        "\n",
        "# Predict344\n",
        "prediction = final_model.predict(input_array)[0]\n",
        "probability = final_model.predict_proba(input_array)[0] if hasattr(final_model, \"predict_proba\") else None\n",
        "\n",
        "#  Show result\n",
        "print(\"\\n🧾 Prediction Result:\")\n",
        "if prediction == 1:\n",
        "    print(\" The person is likely to have diabetes.\")\n",
        "else:\n",
        "    print(\"The person is not likely to have diabetes.\")\n",
        "\n",
        "if probability is not None:\n",
        "    print(f\" Probability of Diabetes: {probability[1]:.2%}\")\n",
        "    print(f\" Probability of No Diabetes: {probability[0]:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFL3FIe7sfuE",
        "outputId": "3e9298b6-1d36-420b-a4f2-efbb44a9388c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔎 Enter patient details to predict diabetes (input numbers as prompted):\n",
            "Enter Pregnancies: 45\n",
            "Enter Glucose: 34\n",
            "Enter BloodPressure: 56\n",
            "Enter SkinThickness: 34\n",
            "Enter Insulin: 56\n",
            "Enter BMI: 23\n",
            "Enter DiabetesPedigreeFunction: 45\n",
            "Enter Age: 66\n",
            "\n",
            "🧾 Prediction Result:\n",
            "🟢 The person is not likely to have diabetes.\n",
            "📊 Probability of Diabetes: 11.17%\n",
            "📊 Probability of No Diabetes: 88.83%\n"
          ]
        }
      ]
    }
  ]
}